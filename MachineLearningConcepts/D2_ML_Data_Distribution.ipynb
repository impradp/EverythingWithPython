{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWZdDOryBGgs"
      },
      "source": [
        "# **Data Sets**\n",
        "\n",
        "In the real world, the data sets are much bigger, but it can be difficult to gather real world data, at least at an early stage of a project.\n",
        "\n",
        "## **Big Data Sets**\n",
        "To create big data sets for testing, we use the Python module NumPy, which comes with a number of methods to create random data sets, of any size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlFC9ozOBtnp",
        "outputId": "ec35b171-4171-4e2e-ea29-ef93c14b5600"
      },
      "outputs": [],
      "source": [
        "# Creatiing 250 random floats between 0 and 5\n",
        "import numpy\n",
        "\n",
        "x = numpy.random.uniform(0.0, 5.0, 250)\n",
        "\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yc6gvF4B8Xo"
      },
      "source": [
        "## **Histogram**\n",
        "While working with number of datas in the program, histogram is often used to properly have a visualization of distribution of the data sets.\n",
        "\n",
        "In the below example,\n",
        "\n",
        "- We use the array from the example above to draw a histogram with 5 bars.\n",
        "- The first bar represents how many values in the array are between 0 and 1.\n",
        "- The second bar represents how many values are between 1 and 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_2-YZ7ItCWct",
        "outputId": "c7a6637a-386d-49ed-bb43-c1cc400f64b1"
      },
      "outputs": [],
      "source": [
        "# Using matplotlib's pyplot to visualize the data sets distribution.\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = numpy.random.uniform(0.0, 5.0, 250)\n",
        "\n",
        "plt.hist(x, 5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erZszQ7CDnX7"
      },
      "source": [
        "## **Normal Data Distribution(Gaussian data distribution)**\n",
        "If an array of data are concentrated around a single value, then it is termed as normal data distribution.\n",
        "\n",
        "In the example below:\n",
        "\n",
        "We use the array from the numpy.random.normal() method, with 100000 values,  to draw a histogram with 100 bars.\n",
        "\n",
        "We specify that the mean value is 5.0, and the standard deviation is 1.0.\n",
        "- Meaning that the values should be concentrated around 5.0, and rarely further away than 1.0 from the mean.\n",
        "- And as you can see from the histogram, most values are between 4.0 and 6.0, with a top at approximately 5.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "e24hRvVQFYxg",
        "outputId": "c1657dd3-3315-4cc5-bff9-27c30c5237ef"
      },
      "outputs": [],
      "source": [
        "# Creating normal data distribution\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = numpy.random.normal(5.0, 1.0, 100000)\n",
        "\n",
        "plt.hist(x, 100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TVQmNGXGHEv"
      },
      "source": [
        "## **Scatter Plot**\n",
        "A scatter plot is a type of data visualization that shows the relationship between two variables by displaying points on a two-dimensional coordinate system.\n",
        "\n",
        "Scatter plot method from matplotlib takes two arrays of the same length, one for the values of the x-axis, and one for the values of the y-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "dkdVoaqMHO96",
        "outputId": "b78707fd-9f4e-44d3-be8d-cdf83cd1b8ae"
      },
      "outputs": [],
      "source": [
        "# Creating scatter plot for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [5,7,8,7,2,17,2,9,4,11,12,9,6]\n",
        "y = [99,86,87,88,111,86,103,87,94,78,77,85,86]\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0bQ1XhmHeh5"
      },
      "source": [
        "## **Random Data Distributions**\n",
        "In Machine Learning the data sets can contain thousands-, or even millions, of values.\n",
        "\n",
        "When it comes to testing out the machine learning algorithms, huge data sets are required for which the values are to be generated randomly.\n",
        "\n",
        "Let us create two arrays that are both filled with 1000 random numbers from a normal data distribution.\n",
        "\n",
        "- The first array will have the mean set to 5.0 with a standard deviation of 1.0.\n",
        "- The second array will have the mean set to 10.0 with a standard deviation of 2.0.\n",
        "\n",
        "***Output***\n",
        "\n",
        "- We can see that the dots are concentrated around the value 5 on the x-axis, and 10 on the y-axis.\n",
        "- We can also see that the spread is wider on the y-axis than on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "gwRtKcIzIXTy",
        "outputId": "578d6bd2-6dbd-43a3-e6cf-b87f7e58d7bf"
      },
      "outputs": [],
      "source": [
        "# Creating 1000 plots randomly.\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = numpy.random.normal(5.0, 1.0, 1000)\n",
        "y = numpy.random.normal(10.0, 2.0, 1000)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dKp6Z5IJBJk"
      },
      "source": [
        "## **Regression**\n",
        "\n",
        "Regression is used when you try to find the relationship between variables.\n",
        "\n",
        "In Machine Learning, and in statistical modeling, that relationship is used to predict the outcome of future events.\n",
        "\n",
        "### **Linear Regression**\n",
        "Linear regression uses the relationship between the data-points to draw a straight line through all them.\n",
        "\n",
        "This line can be used to predict future values.\n",
        "\n",
        "***In the example below,***\n",
        "\n",
        "In the example below, the x-axis represents age, and the y-axis represents speed. We have registered the age and speed of 13 cars as they were passing a tollbooth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "laVK9_9EKBGw",
        "outputId": "f83764a0-007d-4c05-c37d-eb07b70bbe38"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "x = [5,7,8,7,2,17,2,9,4,11,12,9,6]\n",
        "y = [99,86,87,88,111,86,103,87,94,78,77,85,86]\n",
        "\n",
        "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
        "print(stats.linregress(x, y)) # The result -0.76 shows that there is a relationship, not perfect, but it indicates that we could use linear regression in future predictions.\n",
        "\n",
        "def myfunc(x):\n",
        "  return slope * x + intercept\n",
        "\n",
        "mymodel = list(map(myfunc, x))\n",
        "print(myfunc(9))\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, mymodel)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch8m-ubdzorY"
      },
      "source": [
        "## **Correlation Coefficient(R)**\n",
        "\n",
        "R (or R²) is actually an output of linear regression that tells us how well our model fits the data, not a value we choose beforehand. It ranges from -1 to 1 (or 0 to 1 for R²), where:\n",
        "\n",
        "- R = 1 indicates perfect positive correlation\n",
        "- R = -1 indicates perfect negative correlation\n",
        "- R = 0 indicates no linear correlation\n",
        "\n",
        "For making predictions, what you want to look for is:\n",
        "\n",
        "  - A strong R value (closer to -1 or 1)\n",
        "  - Statistical significance of the relationship\n",
        "  - Whether the linear relationship makes logical sense for your data\n",
        "\n",
        "For most real-world predictions, an ***|R| > 0.7*** is considered strong, though the acceptable threshold depends on your specific field and use case.\n",
        "\n",
        "***Key Differences between good fit and bad fit when it comes to using linear regession:***\n",
        "  1.  Good Fit (R ≈ 0.99):\n",
        "\n",
        "    - The points follow a clear upward trend\n",
        "    - Points lie very close to the regression line\n",
        "    - There's a strong linear relationship\n",
        "    - This would be reliable for making predictions\n",
        "\n",
        "\n",
        "  2.  Bad Fit (R ≈ 0.1):\n",
        "\n",
        "    - Points are scattered randomly\n",
        "    - No clear pattern or trend\n",
        "    - The regression line doesn't represent the data well\n",
        "    - This would be unreliable for making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "FyRKxUfo3tVf",
        "outputId": "507f3beb-3f36-40d1-8234-778b7d60a7d9"
      },
      "outputs": [],
      "source": [
        "# Example 1: Bad fit (random data with low correlation)\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Bad fit example\n",
        "x1 = [89, 43, 36, 36, 95, 10, 66, 34, 38, 20, 26, 29, 48, 64, 6, 5, 36, 66, 72, 40]\n",
        "y1 = [21, 46, 3, 35, 67, 95, 53, 72, 58, 10, 26, 34, 90, 33, 38, 20, 56, 2, 47, 15]\n",
        "\n",
        "slope1, intercept1, r1, p1, std_err1 = stats.linregress(x1, y1)\n",
        "\n",
        "def myfunc1(x):\n",
        "    return slope1 * x + intercept1\n",
        "\n",
        "mymodel1 = list(map(myfunc1, x1))\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(x1, y1)\n",
        "plt.plot(x1, mymodel1)\n",
        "plt.title(f'Bad Fit (R = {r1:.2f})')\n",
        "\n",
        "# Good fit example\n",
        "x2 = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "y2 = [15, 23, 29, 34, 40, 45, 55, 60, 65, 70]\n",
        "\n",
        "slope2, intercept2, r2, p2, std_err2 = stats.linregress(x2, y2)\n",
        "\n",
        "def myfunc2(x):\n",
        "    return slope2 * x + intercept2\n",
        "\n",
        "mymodel2 = list(map(myfunc2, x2))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(x2, y2)\n",
        "plt.plot(x2, mymodel2)\n",
        "plt.title(f'Good Fit (R = {r2:.2f})')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aao7FYib5hZ9"
      },
      "source": [
        "## **Polynomial Regression**\n",
        "\n",
        "Polynomial regression, like linear regression, uses the relationship between the variables x and y to find the best way to draw a line through the data points.\n",
        "\n",
        "It might be ideal when your data points clearly will not fit a linear regression (a straight line through all data points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "lb-SUv-Z6KXw",
        "outputId": "61bb5b21-5228-4389-ac53-e864784b0bab"
      },
      "outputs": [],
      "source": [
        "# Creating polynomial regression for data sets(not applicable for linear regression)\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
        "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
        "\n",
        "mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n",
        "\n",
        "myline = numpy.linspace(1, 22, 100)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot(myline, mymodel(myline))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmFMjaxu7CC2"
      },
      "source": [
        "### **R-Squared**\n",
        "R-squared measures the proportion of variance explained by the model.\n",
        "\n",
        "It is important to know how well the relationship between the values of the x- and y-axis is, if there are no relationship the polynomial regression can not be used to predict anything.\n",
        "\n",
        "*The r-squared value ranges from 0 to 1, where 0 means no relationship, and 1 means 100% related.*\n",
        "\n",
        "However,\n",
        "\n",
        "  - Higher R-squared doesn't always mean better model\n",
        "  - Polynomial regression can overfit, especially with higher degrees\n",
        "  - Need to balance between R-squared and model complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqAh1Dw88CnE",
        "outputId": "4f6c792f-0ae8-43b0-f547-3917f02f3744"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
        "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
        "\n",
        "mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n",
        "\n",
        "print(r2_score(y, mymodel(x)))\n",
        "\n",
        "# The result 0.94 shows that there is a very good relationship,\n",
        "# and we can use polynomial regression in future predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWxq1Nzf8f-A"
      },
      "source": [
        "### **Prediction Using Models**\n",
        "\n",
        "As we knew that, the model is somewhat best fit as polynomial regression since value is way closer to 1; we can use this model to predict the future y-values for corresponding x-values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "WtO9WDMG9MCd",
        "outputId": "0ad7f908-2451-4caa-e7ef-64458266731d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
        "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
        "\n",
        "mymodel = np.poly1d(np.polyfit(x, y, 3))\n",
        "\n",
        "my_new_value = mymodel(17)\n",
        "print(my_new_value)\n",
        "\n",
        "myline = np.linspace(1, 22, 100)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot(myline, mymodel(myline))\n",
        "# Add just one point to highlight the prediction\n",
        "plt.scatter(17, my_new_value, color='red', s=100)  # red point, slightly larger size\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL6NW1Wu-1X4"
      },
      "source": [
        "### **Bad Fit (For Polynomial Regression)**\n",
        "If you get a very low r-squared value(closer to 0), then it will be a bad fit.\n",
        "\n",
        "Refer the example below for understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "WGSaAjMf_PXQ",
        "outputId": "8beea46a-72fe-4e6b-9355-dbd85208620d"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "x = [89,43,36,36,95,10,66,34,38,20,26,29,48,64,6,5,36,66,72,40]\n",
        "y = [21,46,3,35,67,95,53,72,58,10,26,34,90,33,38,20,56,2,47,15]\n",
        "\n",
        "mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n",
        "\n",
        "print(r2_score(y, mymodel(x))) # which is very low i.e close to zero.\n",
        "\n",
        "myline = np.linspace(5, 95, 100)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.plot(myline, mymodel(myline))\n",
        "plt.show()\n",
        "# This plotted line doesnot signify any of the scattered plots in the given space.\n",
        "# Thus, by evaluating the r-squared, we can determine if polynomial regression will be a good or bad fit for the given dataset."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
